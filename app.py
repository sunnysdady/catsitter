import streamlit as st
import pandas as pd
import requests
import pydeck as pdk
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import numpy as np
import re
import io
import calendar

# --- 1. æ ¸å¿ƒé…ç½® ---
def clean_id(raw_id):
    if not raw_id: return ""
    match = re.search(r'[a-zA-Z0-9]{15,}', str(raw_id))
    return match.group(0).strip() if match else str(raw_id).strip()

APP_ID = st.secrets.get("FEISHU_APP_ID", "").strip()
APP_SECRET = st.secrets.get("FEISHU_APP_SECRET", "").strip()
APP_TOKEN = clean_id(st.secrets.get("FEISHU_APP_TOKEN", "MdvxbpyUHaFkWksl4B6cPlfpn2f")) 
TABLE_ID = clean_id(st.secrets.get("FEISHU_TABLE_ID", "tbl6Ziz0dO1evH7s")) 
AMAP_API_KEY = st.secrets.get("AMAP_KEY", "").strip()

# --- 2. è°ƒåº¦ä¸å¯¹è´¦å¼•æ“ ---

def calculate_billing_days(row, start_range, end_range):
    """è®¡ç®—å‘¨æœŸå†…è®¡è´¹å¤©æ•°ï¼š1=æ¯å¤©, 2=éš”å¤©"""
    try:
        s_date = pd.to_datetime(row['æœåŠ¡å¼€å§‹æ—¥æœŸ']).date()
        e_date = pd.to_datetime(row['æœåŠ¡ç»“æŸæ—¥æœŸ']).date()
        freq = int(row.get('æŠ•å–‚é¢‘ç‡', 1))
        actual_start, actual_end = max(s_date, start_range), min(e_date, end_range)
        if actual_start > actual_end: return 0
        count = 0
        current = actual_start
        while current <= actual_end:
            if (current - s_date).days % freq == 0: count += 1
            current += timedelta(days=1)
        return count
    except: return 0

def optimize_route(df_sitter):
    if len(df_sitter) <= 1:
        df_sitter['æ‹Ÿå®šé¡ºåº'] = range(1, len(df_sitter) + 1)
        return df_sitter
    unvisited = df_sitter.to_dict('records')
    current_node = unvisited.pop(0)
    optimized_list = [current_node]
    while unvisited:
        next_node = min(unvisited, key=lambda x: np.sqrt((current_node['lng']-x['lng'])**2 + (current_node['lat']-x['lat'])**2))
        unvisited.remove(next_node)
        optimized_list.append(next_node)
        current_node = next_node
    res_df = pd.DataFrame(optimized_list)
    res_df['æ‹Ÿå®šé¡ºåº'] = range(1, len(res_df) + 1)
    return res_df

def execute_smart_dispatch(df, active_sitters):
    if 'å–‚çŒ«å¸ˆ' not in df.columns: df['å–‚çŒ«å¸ˆ'] = ""
    df['å–‚çŒ«å¸ˆ'] = df['å–‚çŒ«å¸ˆ'].fillna("")
    sitter_load = {s: 0 for s in active_sitters}
    for s in df['å–‚çŒ«å¸ˆ']:
        if s in sitter_load: sitter_load[s] += 1
    for i, row in df.iterrows():
        if str(row.get('å–‚çŒ«å¸ˆ', '')).strip() not in ["", "nan"]: continue
        if active_sitters:
            best = min(sitter_load, key=sitter_load.get)
            df.at[i, 'å–‚çŒ«å¸ˆ'] = best
            sitter_load[best] += 1
    return df

# --- 3. é£ä¹¦ API äº¤äº’ ---

def get_feishu_token():
    try:
        r = requests.post("https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal", json={"app_id": APP_ID, "app_secret": APP_SECRET}, timeout=10)
        return r.json().get("tenant_access_token")
    except: return None

def fetch_feishu_data():
    token = get_feishu_token()
    if not token: return pd.DataFrame()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records"
    try:
        r = requests.get(url, headers={"Authorization": f"Bearer {token}"}, params={"page_size": 500}, timeout=15).json()
        items = r.get("data", {}).get("items", [])
        if not items: return pd.DataFrame()
        df = pd.DataFrame([dict(i['fields'], _system_id=i['record_id']) for i in items])
        for c in ['æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ']:
            if c in df.columns: df[c] = pd.to_datetime(df[c], unit='ms', errors='coerce')
        if 'è¿›åº¦' not in df.columns: df['è¿›åº¦'] = "æœªå®Œæˆ"
        if 'è®¢å•çŠ¶æ€' not in df.columns: df['è®¢å•çŠ¶æ€'] = "è¿›è¡Œä¸­"
        for col in ['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'å¤‡æ³¨', 'lng', 'lat', 'æŠ•å–‚é¢‘ç‡']:
            if col not in df.columns: df[col] = ""
        return df
    except: return pd.DataFrame()

def update_feishu_field(record_id, field_name, value):
    token = get_feishu_token()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records/{str(record_id).strip()}"
    payload = {"fields": {field_name: str(value)}}
    try:
        r = requests.patch(url, headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"}, json=payload, timeout=10)
        return r.status_code == 200
    except: return False

def generate_excel_v64(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df[['ä½œä¸šæ—¥æœŸ', 'æ‹Ÿå®šé¡ºåº', 'å–‚çŒ«å¸ˆ', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name='æ±‡æ€»')
        df.drop_duplicates(subset=['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€'])[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name='å® ç‰©å½’å±æ˜ç»†')
        for s in df['å–‚çŒ«å¸ˆ'].unique():
            if str(s).strip() and str(s) != 'nan':
                df[df['å–‚çŒ«å¸ˆ'] == s][['ä½œä¸šæ—¥æœŸ', 'æ‹Ÿå®šé¡ºåº', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name=str(s)[:31])
    return output.getvalue()

# --- 4. è§†è§‰å¯¹é½ ---

st.set_page_config(page_title="æŒ‡æŒ¥ä¸­å¿ƒ V64.0", layout="wide")

def set_ui():
    st.markdown("""
        <style>
        .main-nav [data-testid="stVerticalBlock"] div.stButton > button {
            width: 200px !important; height: 50px !important; border-radius: 10px !important;
            font-size: 18px !important; font-weight: 800 !important; box-shadow: 4px 4px 0px #000;
            background-color: #FFFFFF !important; margin-bottom: 12px !important; display: block; margin-left: auto; margin-right: auto;
        }
        .quick-nav div.stButton > button {
            width: 100px !important; height: 25px !important; font-size: 12px !important;
            border: 1.5px solid #000 !important; border-radius: 4px !important; box-shadow: 1.5px 1.5px 0px #000;
        }
        .stMetric { background: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #ddd; }
        </style>
        """, unsafe_allow_html=True)

set_ui()

@st.cache_data(show_spinner=False)
def get_coords(address):
    url = f"https://restapi.amap.com/v3/geocode/geo?key={AMAP_API_KEY}&address=æ·±åœ³å¸‚{address}"
    try:
        r = requests.get(url, timeout=5).json()
        if r['status'] == '1' and r['geocodes']:
            loc = r['geocodes'][0]['location'].split(',')
            return float(loc[0]), float(loc[1])
    except: pass
    return None, None

# --- 5. ä¾§è¾¹æ å¸ƒå±€ (V44 å¯¹é½) ---

if 'page' not in st.session_state: st.session_state['page'] = "æ™ºèƒ½çœ‹æ¿"
if 'feishu_cache' not in st.session_state: st.session_state['feishu_cache'] = fetch_feishu_data()

with st.sidebar:
    st.subheader("ğŸ“… å¿«æ·è°ƒåº¦ (100*25)")
    st.markdown('<div class="quick-nav">', unsafe_allow_html=True)
    td = datetime.now().date()
    cq1, cq2 = st.columns(2)
    with cq1:
        if st.button("ğŸ“ ä»Šå¤©"): st.session_state['r'] = (td, td + timedelta(days=1))
        if st.button("ğŸ“ æœ¬å‘¨"): st.session_state['r'] = (td - timedelta(days=td.weekday()), td + timedelta(days=(6-td.weekday())+1))
    with cq2:
        if st.button("ğŸ“ æ˜å¤©"): st.session_state['r'] = (td + timedelta(days=1), td + timedelta(days=2))
        if st.button("ğŸ“ æœ¬æœˆ"): st.session_state['r'] = (td.replace(day=1), td.replace(day=calendar.monthrange(td.year, td.month)[1]) + timedelta(days=1))
    st.markdown('</div>', unsafe_allow_html=True)
    
    d_sel = st.date_input("è°ƒåº¦åŒºé—´", value=st.session_state.get('r', (td, td + timedelta(days=1))))
    
    # çŠ¶æ€ç­›é€‰å™¨
    st.divider()
    s_filter = st.multiselect("ğŸ” è®¢å•çŠ¶æ€è¿‡æ»¤", options=["è¿›è¡Œä¸­", "å·²ç»“æŸ", "å¾…å¤„ç†"], default=["è¿›è¡Œä¸­"])
    
    sitters = ["æ¢¦è•Š", "ä¾è•Š"]
    active = [s for s in sitters if st.checkbox(f"{s} (å‡ºå‹¤)", value=True, key=f"active_{s}")]
    
    st.divider()
    st.markdown('<div class="main-nav">', unsafe_allow_html=True)
    if st.button("ğŸ“‚ æ•°æ®ä¸­å¿ƒ"): st.session_state['page'] = "æ•°æ®ä¸­å¿ƒ"
    if st.button("ğŸ“Š ä»»åŠ¡è¿›åº¦"): st.session_state['page'] = "ä»»åŠ¡è¿›åº¦"
    if st.button("ğŸ“ è®¢å•ä¿¡æ¯"): st.session_state['page'] = "è®¢å•ä¿¡æ¯"
    if st.button("ğŸš€ æ™ºèƒ½çœ‹æ¿"): st.session_state['page'] = "æ™ºèƒ½çœ‹æ¿"
    if st.button("ğŸ“– å¸®åŠ©æ–‡æ¡£"): st.session_state['page'] = "å¸®åŠ©æ–‡æ¡£"
    st.markdown('</div>', unsafe_allow_html=True)

# --- 6. å„é¢‘é“é€»è¾‘æ¸²æŸ“ ---

# è®¢å•ä¿¡æ¯ï¼šæ‰¾å›ç­›é€‰ä¸å¯¹è´¦
if st.session_state['page'] == "è®¢å•ä¿¡æ¯":
    st.title("ğŸ“ è®¢å•å…¨æ™¯åˆ†æ (è´¢åŠ¡å¯¹è´¦)")
    df_raw = st.session_state['feishu_cache'].copy()
    if not df_raw.empty:
        df_i = df_raw[df_raw['è®¢å•çŠ¶æ€'].isin(s_filter)] if s_filter else df_raw
        if isinstance(d_sel, tuple) and len(d_sel) == 2:
            df_i['è®¡è´¹å¤©æ•°'] = df_i.apply(lambda r: calculate_billing_days(r, d_sel[0], d_sel[1]), axis=1)
            st.metric("ğŸ“Š å½“å‰å‘¨æœŸæ€»è®¡è´¹å¤©æ•°", f"{df_i['è®¡è´¹å¤©æ•°'].sum()} æ¬¡ä¸Šé—¨")
        
        s_query = st.text_input("ğŸ” ç§’æœå® ç‰©", placeholder="è¾“å…¥å°çŒ«å...")
        if s_query: df_i = df_i[df_i['å® ç‰©åå­—'].str.contains(s_query, na=False)]
        
        with ThreadPoolExecutor(max_workers=5) as ex: coords = list(ex.map(get_coords, df_i['è¯¦ç»†åœ°å€']))
        df_i[['lng', 'lat']] = pd.DataFrame(coords, index=df_i.index, columns=['lng', 'lat'])
        st.dataframe(df_i[['å® ç‰©åå­—', 'è®¡è´¹å¤©æ•°', 'æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ', 'æŠ•å–‚é¢‘ç‡', 'è®¢å•çŠ¶æ€', 'å–‚çŒ«å¸ˆ', 'è¯¦ç»†åœ°å€']], use_container_width=True)

# æ™ºèƒ½çœ‹æ¿ï¼šæ‰¾å›äººå‘˜ç­›é€‰åŠŸèƒ½
elif st.session_state['page'] == "æ™ºèƒ½çœ‹æ¿":
    st.title("ğŸš€ è°ƒåº¦æŒ‡æŒ¥å¤§å±")
    df_raw = st.session_state['feishu_cache'].copy()
    if not df_raw.empty and isinstance(d_sel, tuple) and len(d_sel) == 2:
        df_kb = df_raw[df_raw['è®¢å•çŠ¶æ€'].isin(s_filter)] if s_filter else df_raw
        if st.button("âœ¨ æ‹Ÿå®šæœ€ä¼˜è°ƒåº¦æ–¹æ¡ˆ"):
            ap = []; dk = execute_smart_dispatch(df_kb, active)
            days = pd.date_range(d_sel[0], d_sel[1]).tolist()
            for d in days:
                ct = pd.Timestamp(d); d_v = dk[(dk['æœåŠ¡å¼€å§‹æ—¥æœŸ'] <= ct) & (dk['æœåŠ¡ç»“æŸæ—¥æœŸ'] >= ct)].copy()
                if not d_v.empty:
                    d_v = d_v[d_v.apply(lambda r: (ct - r['æœåŠ¡å¼€å§‹æ—¥æœŸ']).days % int(r.get('æŠ•å–‚é¢‘ç‡', 1)) == 0, axis=1)]
                    if not d_v.empty:
                        with ThreadPoolExecutor(max_workers=5) as ex: coords = list(ex.map(get_coords, d_v['è¯¦ç»†åœ°å€']))
                        d_v[['lng', 'lat']] = pd.DataFrame(coords, index=d_v.index, columns=['lng', 'lat'])
                        dv = d_v.dropna(subset=['lng', 'lat']).copy()
                        for s in active:
                            stks = dv[dv['å–‚çŒ«å¸ˆ'] == s].copy()
                            if not stks.empty:
                                res = optimize_route(stks); res['ä½œä¸šæ—¥æœŸ'] = d.strftime('%Y-%m-%d'); ap.append(res)
            st.session_state['fp'] = pd.concat(ap) if ap else None
            st.success("âœ… æ–¹æ¡ˆæ‹Ÿå®šå®Œæˆï¼")

        if st.session_state.get('fp') is not None:
            st.download_button("ğŸ“¥ å¯¼å‡º Excel (å«å½’å±æ˜ç»†)", data=generate_excel_v64(st.session_state['fp']), file_name="Cat_Dispatch_V64.xlsx")
            c1, c2 = st.columns(2)
            vd = c1.selectbox("ğŸ“… æŸ¥çœ‹æ—¥æœŸ", sorted(st.session_state['fp']['ä½œä¸šæ—¥æœŸ'].unique()))
            # æ¢å¤äººå‘˜ç­›é€‰å™¨
            vs = c2.selectbox("ğŸ‘¤ ç­›é€‰äººå‘˜", ["å…¨éƒ¨"] + sorted(st.session_state['fp'][st.session_state['fp']['ä½œä¸šæ—¥æœŸ'] == vd]['å–‚çŒ«å¸ˆ'].unique().tolist()))
            v_data = st.session_state['fp'][st.session_state['fp']['ä½œä¸šæ—¥æœŸ'] == vd]
            if vs != "å…¨éƒ¨": v_data = v_data[v_data['å–‚çŒ«å¸ˆ'] == vs]
            
            if not v_data.empty:
                st.pydeck_chart(pdk.Deck(map_style=pdk.map_styles.LIGHT, initial_view_state=pdk.ViewState(longitude=v_data['lng'].mean(), latitude=v_data['lat'].mean(), zoom=11),
                    layers=[pdk.Layer("ScatterplotLayer", v_data, get_position='[lng, lat]', get_color='[0, 123, 255, 180]' if vs=="æ¢¦è•Š" else '[255, 165, 0, 180]', get_radius=350)]))
                st.data_editor(v_data[['æ‹Ÿå®šé¡ºåº', 'å–‚çŒ«å¸ˆ', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].sort_values('æ‹Ÿå®šé¡ºåº'), use_container_width=True)

# æ•°æ®ä¸­å¿ƒï¼šæ”¯æŒè®¢å•çŠ¶æ€ä¿®æ”¹
elif st.session_state['page'] == "æ•°æ®ä¸­å¿ƒ":
    st.title("ğŸ“‚ æ•°æ®å¿«ç…§ä¸çŠ¶æ€æ§åˆ¶å°")
    df_dc = st.session_state['feishu_cache'].copy()
    if not df_dc.empty:
        st.subheader("ğŸ› ï¸ äº‘ç«¯è®¢å•çŠ¶æ€ç»´æŠ¤ (å®æ—¶åŒæ­¥)")
        edit_dc = st.data_editor(df_dc[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'è®¢å•çŠ¶æ€']], 
                                 column_config={"è®¢å•çŠ¶æ€": st.column_config.SelectboxColumn("ä¿®æ”¹çŠ¶æ€", options=["è¿›è¡Œä¸­", "å·²ç»“æŸ", "å¾…å¤„ç†"], required=True)}, 
                                 use_container_width=True)
        if st.button("ğŸš€ æäº¤çŠ¶æ€ä¿®æ”¹è‡³é£ä¹¦"):
            sc = 0
            for i, row in edit_dc.iterrows():
                if row['è®¢å•çŠ¶æ€'] != df_dc.iloc[i]['è®¢å•çŠ¶æ€']:
                    if update_feishu_field(df_dc.iloc[i]['_system_id'], "è®¢å•çŠ¶æ€", row['è®¢å•çŠ¶æ€']): sc += 1
            st.success(f"å·²åŒæ­¥ {sc} ä¸ªè®¢å•çŠ¶æ€ã€‚"); st.session_state.pop('feishu_cache', None); st.rerun()
    
    st.divider()
    with st.expander("æ‰¹é‡å¯¼å…¥ Excel"):
        up = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=["xlsx"])
        if up and st.button("ğŸš€ æ¨é€äº‘ç«¯"):
            du = pd.read_excel(up); pb = st.progress(0); tk = get_feishu_token()
            for i, (_, r) in enumerate(du.iterrows()):
                f = {"è¯¦ç»†åœ°å€": str(r['è¯¦ç»†åœ°å€']).strip(), "å® ç‰©åå­—": str(r.get('å® ç‰©åå­—', 'å°çŒ«')).strip(), "æœåŠ¡å¼€å§‹æ—¥æœŸ": int(datetime.combine(pd.to_datetime(r['æœåŠ¡å¼€å§‹æ—¥æœŸ']), datetime.min.time()).timestamp()*1000), "æœåŠ¡ç»“æŸæ—¥æœŸ": int(datetime.combine(pd.to_datetime(r['æœåŠ¡ç»“æŸæ—¥æœŸ']), datetime.min.time()).timestamp()*1000)}
                requests.post(f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records", headers={"Authorization": f"Bearer {tk}"}, json={"fields": f})
                pb.progress((i + 1) / len(du))
            st.success("åŒæ­¥æˆåŠŸï¼"); st.session_state.pop('feishu_cache', None); st.rerun()

# ä»»åŠ¡è¿›åº¦ä¸å¸®åŠ©æ–‡æ¡£é€»è¾‘ä¿æŒä¸€è‡´
elif st.session_state['page'] == "ä»»åŠ¡è¿›åº¦":
    st.title("ğŸ“Š ä»»åŠ¡æ‰§è¡Œå®æ—¶åé¦ˆ")
    df_p = st.session_state['feishu_cache'].copy()
    if not df_p.empty:
        edit = st.data_editor(df_p[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'è¿›åº¦']], column_config={"è¿›åº¦": st.column_config.SelectboxColumn("æ‰§è¡ŒçŠ¶æ€", options=["æœªå¼€å§‹", "å·²å‡ºå‘", "æœåŠ¡ä¸­", "å·²å®Œæˆ"])}, use_container_width=True)
        if st.button("ğŸš€ åŒæ­¥è¿›åº¦"):
            for i, row in edit.iterrows():
                if row['è¿›åº¦'] != df_p.iloc[i]['è¿›åº¦']: update_feishu_field(df_p.iloc[i]['_system_id'], "è¿›åº¦", row['è¿›åº¦'])
            st.success("åŒæ­¥æˆåŠŸï¼"); st.session_state.pop('feishu_cache', None); st.rerun()

elif st.session_state['page'] == "å¸®åŠ©æ–‡æ¡£":
    st.title("ğŸ“– V64.0 æ“ä½œæŒ‡å¼•")
    st.markdown("""
    1. **å¦‚ä½•ç®¡ç†è®¢å•ï¼Ÿ**ï¼šåœ¨ã€æ•°æ®ä¸­å¿ƒã€‘çš„ä¸Šæ–¹ç¼–è¾‘å™¨ç›´æ¥ä¿®æ”¹è®¢å•çŠ¶æ€ä¸ºâ€œå·²ç»“æŸâ€ï¼Œç‚¹å‡»æäº¤å³å¯ï¼Œ**ä¸éœ€è¦å»é£ä¹¦å‹¾é€‰**ã€‚
    2. **ç­›é€‰åœ¨å“ªï¼Ÿ**ï¼šè¿›å…¥ã€æ™ºèƒ½çœ‹æ¿ã€‘æ‹Ÿå®šæ–¹æ¡ˆåï¼Œæ—¥æœŸä¸‹æ–¹ä¼šå‡ºç°ã€ğŸ‘¤ ç­›é€‰äººå‘˜ã€‘ä¸‹æ‹‰æ¡†ï¼Œæ”¯æŒåªçœ‹æ¢¦è•Šæˆ–ä¾è•Šã€‚
    3. **è´¢åŠ¡å¯¹è´¦**ï¼šã€è®¢å•ä¿¡æ¯ã€‘é¡¶éƒ¨ä¼šæ˜¾ç¤ºæ€»è®¡è´¹å¤©æ•°ï¼Œå·²è‡ªåŠ¨æ ¹æ®çŠ¶æ€è¿‡æ»¤ç»“æœè®¡ç®—ã€‚
    """)

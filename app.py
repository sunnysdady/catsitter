import streamlit as st
import pandas as pd
import requests
import pydeck as pdk
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import numpy as np
import re
import io
import calendar

# --- 1. æ ¸å¿ƒé…ç½® ---
def clean_id(raw_id):
    if not raw_id: return ""
    match = re.search(r'[a-zA-Z0-9]{15,}', str(raw_id))
    return match.group(0).strip() if match else str(raw_id).strip()

APP_ID = st.secrets.get("FEISHU_APP_ID", "").strip()
APP_SECRET = st.secrets.get("FEISHU_APP_SECRET", "").strip()
APP_TOKEN = clean_id(st.secrets.get("FEISHU_APP_TOKEN", "MdvxbpyUHaFkWksl4B6cPlfpn2f")) 
TABLE_ID = clean_id(st.secrets.get("FEISHU_TABLE_ID", "tbl6Ziz0dO1evH7s")) 
AMAP_API_KEY = st.secrets.get("AMAP_KEY", "").strip()

# --- 2. æ ¸å¿ƒé€»è¾‘å¼•æ“ ---

def calculate_billing_days(row, start_range, end_range):
    """ç²¾ç¡®è®¡ç®—è®¡è´¹å¤©æ•°ï¼š1=æ¯å¤©, 2=éš”å¤©"""
    try:
        s_date = pd.to_datetime(row['æœåŠ¡å¼€å§‹æ—¥æœŸ']).date()
        e_date = pd.to_datetime(row['æœåŠ¡ç»“æŸæ—¥æœŸ']).date()
        freq = int(row.get('æŠ•å–‚é¢‘ç‡', 1))
        actual_start, actual_end = max(s_date, start_range), min(e_date, end_range)
        if actual_start > actual_end: return 0
        count = 0; current = actual_start
        while current <= actual_end:
            if (current - s_date).days % freq == 0: count += 1
            current += timedelta(days=1)
        return count
    except: return 0

def optimize_route(df_sitter):
    """è·¯å¾„ä¼˜åŒ–ï¼ˆä»…é’ˆå¯¹æœ‰åæ ‡çš„ç‚¹ä½ï¼‰"""
    has_coords = df_sitter.dropna(subset=['lng', 'lat']).copy()
    no_coords = df_sitter[df_sitter['lng'].isna()].copy()
    
    if len(has_coords) <= 1:
        res = pd.concat([has_coords, no_coords])
        res['æ‹Ÿå®šé¡ºåº'] = range(1, len(res) + 1)
        return res
        
    unvisited = has_coords.to_dict('records')
    current_node = unvisited.pop(0)
    optimized_list = [current_node]
    while unvisited:
        next_node = min(unvisited, key=lambda x: np.sqrt((current_node['lng']-x['lng'])**2 + (current_node['lat']-x['lat'])**2))
        unvisited.remove(next_node)
        optimized_list.append(next_node)
        current_node = next_node
        
    res_df = pd.concat([pd.DataFrame(optimized_list), no_coords])
    res_df['æ‹Ÿå®šé¡ºåº'] = range(1, len(res_df) + 1)
    return res_df

def execute_smart_dispatch(df, active_sitters):
    if 'å–‚çŒ«å¸ˆ' not in df.columns: df['å–‚çŒ«å¸ˆ'] = ""
    df['å–‚çŒ«å¸ˆ'] = df['å–‚çŒ«å¸ˆ'].fillna("")
    sitter_load = {s: 0 for s in active_sitters}
    for s in df['å–‚çŒ«å¸ˆ']:
        if s in sitter_load: sitter_load[s] += 1
    for i, row in df.iterrows():
        if str(row.get('å–‚çŒ«å¸ˆ', '')).strip() not in ["", "nan"]: continue
        if active_sitters:
            best = min(sitter_load, key=sitter_load.get)
            df.at[i, 'å–‚çŒ«å¸ˆ'] = best
            sitter_load[best] += 1
    return df

# --- 3. é£ä¹¦ API äº¤äº’ ---

def get_feishu_token():
    try:
        r = requests.post("https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal", json={"app_id": APP_ID, "app_secret": APP_SECRET}, timeout=10)
        return r.json().get("tenant_access_token")
    except: return None

def fetch_feishu_data():
    token = get_feishu_token()
    if not token: return pd.DataFrame()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records"
    try:
        r = requests.get(url, headers={"Authorization": f"Bearer {token}"}, params={"page_size": 500}, timeout=15).json()
        items = r.get("data", {}).get("items", [])
        if not items: return pd.DataFrame()
        df = pd.DataFrame([dict(i['fields'], _system_id=i['record_id']) for i in items])
        for c in ['æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ']:
            if c in df.columns: df[c] = pd.to_datetime(df[c], unit='ms', errors='coerce')
        if 'è¿›åº¦' not in df.columns: df['è¿›åº¦'] = "æœªå®Œæˆ"
        if 'è®¢å•çŠ¶æ€' not in df.columns: df['è®¢å•çŠ¶æ€'] = "è¿›è¡Œä¸­"
        for col in ['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'å¤‡æ³¨', 'lng', 'lat', 'æŠ•å–‚é¢‘ç‡']:
            if col not in df.columns: df[col] = ""
        return df
    except: return pd.DataFrame()

def update_feishu_field(record_id, field_name, value):
    token = get_feishu_token()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records/{str(record_id).strip()}"
    payload = {"fields": {field_name: str(value)}}
    try:
        r = requests.patch(url, headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"}, json=payload, timeout=10)
        return r.status_code == 200
    except: return False

def generate_excel_v67(df):
    """ã€V67 å…¨é‡ç‰ˆã€‘å¯¼å‡ºæ‰€æœ‰è®°å½•ï¼Œä¸å†è¿‡æ»¤"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df[['ä½œä¸šæ—¥æœŸ', 'æ‹Ÿå®šé¡ºåº', 'å–‚çŒ«å¸ˆ', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name='æ±‡æ€»')
        df.drop_duplicates(subset=['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€'])[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name='å® ç‰©å½’å±æ˜ç»†')
        for s in df['å–‚çŒ«å¸ˆ'].unique():
            if str(s).strip() and str(s) != 'nan':
                df[df['å–‚çŒ«å¸ˆ'] == s][['ä½œä¸šæ—¥æœŸ', 'æ‹Ÿå®šé¡ºåº', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name=str(s)[:31])
    return output.getvalue()

# --- 4. è§†è§‰æ–¹æ¡ˆ ---

st.set_page_config(page_title="æŒ‡æŒ¥ä¸­å¿ƒ V67.0", layout="wide")

def set_ui():
    st.markdown("""
        <style>
        .main-nav [data-testid="stVerticalBlock"] div.stButton > button {
            width: 200px !important; height: 50px !important; border-radius: 10px !important;
            font-size: 18px !important; font-weight: 800 !important; box-shadow: 4px 4px 0px #000;
            background-color: #FFFFFF !important; margin-bottom: 12px !important; display: block; margin-left: auto; margin-right: auto;
        }
        .quick-nav div.stButton > button {
            width: 100px !important; height: 25px !important; font-size: 11px !important;
            border: 1.5px solid #000 !important; border-radius: 4px !important; box-shadow: 1.5px 1.5px 0px #000;
        }
        .stMetric { background: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #ddd; }
        </style>
        """, unsafe_allow_html=True)

set_ui()

@st.cache_data(show_spinner=False)
def get_coords(address):
    url = f"https://restapi.amap.com/v3/geocode/geo?key={AMAP_API_KEY}&address=æ·±åœ³å¸‚{address}"
    try:
        r = requests.get(url, timeout=5).json()
        if r['status'] == '1' and r['geocodes']:
            loc = r['geocodes'][0]['location'].split(',')
            return float(loc[0]), float(loc[1])
    except: pass
    return None, None

# --- 5. ä¾§è¾¹æ å¸ƒå±€ ---

if 'page' not in st.session_state: st.session_state['page'] = "æ™ºèƒ½çœ‹æ¿"
if 'feishu_cache' not in st.session_state: st.session_state['feishu_cache'] = fetch_feishu_data()

with st.sidebar:
    st.subheader("ğŸ“… å¿«æ·è°ƒåº¦ (100*25)")
    st.markdown('<div class="quick-nav">', unsafe_allow_html=True)
    td = datetime.now().date()
    cq1, cq2 = st.columns(2)
    with cq1:
        if st.button("ğŸ“ ä»Šå¤©"): st.session_state['r'] = (td, td + timedelta(days=1))
        if st.button("ğŸ“ æœ¬å‘¨"): st.session_state['r'] = (td - timedelta(days=td.weekday()), td + timedelta(days=(6-td.weekday())+1))
    with cq2:
        if st.button("ğŸ“ æ˜å¤©"): st.session_state['r'] = (td + timedelta(days=1), td + timedelta(days=2))
        if st.button("ğŸ“ æœ¬æœˆ"): st.session_state['r'] = (td.replace(day=1), td.replace(day=calendar.monthrange(td.year, td.month)[1]) + timedelta(days=1))
    st.markdown('</div>', unsafe_allow_html=True)
    
    d_sel = st.date_input("è°ƒåº¦æ—¥æœŸèŒƒå›´", value=st.session_state.get('r', (td, td + timedelta(days=1))))
    s_filter = st.multiselect("ğŸ” è®¢å•çŠ¶æ€è¿‡æ»¤", options=["è¿›è¡Œä¸­", "å·²ç»“æŸ", "å¾…å¤„ç†"], default=["è¿›è¡Œä¸­"])
    active = [s for s in ["æ¢¦è•Š", "ä¾è•Š"] if st.checkbox(f"{s} (å‡ºå‹¤)", value=True, key=f"active_{s}")]
    
    st.divider()
    st.markdown('<div class="main-nav">', unsafe_allow_html=True)
    for p in ["æ•°æ®ä¸­å¿ƒ", "ä»»åŠ¡è¿›åº¦", "è®¢å•ä¿¡æ¯", "æ™ºèƒ½çœ‹æ¿"]:
        if st.button(f"ğŸš€ {p}"): st.session_state['page'] = p

# --- 6. æ ¸å¿ƒé¢‘é“æ¸²æŸ“ ---

if st.session_state['page'] == "è®¢å•ä¿¡æ¯":
    st.title("ğŸ“ è®¢å•åˆ†æ (100% å…¨é‡å¯¹è´¦)")
    df_raw = st.session_state['feishu_cache'].copy()
    if not df_raw.empty:
        df_i = df_raw[df_raw['è®¢å•çŠ¶æ€'].isin(s_filter)] if s_filter else df_raw
        if isinstance(d_sel, tuple) and len(d_sel) == 2:
            df_i['è®¡è´¹å¤©æ•°'] = df_i.apply(lambda r: calculate_billing_days(r, d_sel[0], d_sel[1]), axis=1)
            st.metric("ğŸ“Š å½“å‰å‘¨æœŸæ€»è®¡è´¹å¤©æ•°æ±‡æ€»", f"{df_i['è®¡è´¹å¤©æ•°'].sum()} æ¬¡ä¸Šé—¨")
        
        s_query = st.text_input("ğŸ” æœç´¢å® ç‰©", placeholder="è¾“å…¥å°çŒ«å...")
        if s_query: df_i = df_i[df_i['å® ç‰©åå­—'].str.contains(s_query, na=False)]
        
        st.dataframe(df_i[['å® ç‰©åå­—', 'è®¡è´¹å¤©æ•°', 'æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ', 'æŠ•å–‚é¢‘ç‡', 'è®¢å•çŠ¶æ€', 'å–‚çŒ«å¸ˆ', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']], use_container_width=True)

elif st.session_state['page'] == "æ™ºèƒ½çœ‹æ¿":
    st.title("ğŸš€ è°ƒåº¦æŒ‡æŒ¥å¤§å± (å…¨é‡æ´¾å•)")
    df_raw = st.session_state['feishu_cache'].copy()
    if not df_raw.empty and isinstance(d_sel, tuple) and len(d_sel) == 2:
        df_kb = df_raw[df_raw['è®¢å•çŠ¶æ€'].isin(s_filter)] if s_filter else df_raw
        if st.button("âœ¨ 1. æ‹Ÿå®šå…¨é‡æ–¹æ¡ˆ"):
            ap = []
            dk = execute_smart_dispatch(df_kb, active)
            days = pd.date_range(d_sel[0], d_sel[1]).tolist()
            for d in days:
                ct = pd.Timestamp(d)
                d_v = dk[(dk['æœåŠ¡å¼€å§‹æ—¥æœŸ'] <= ct) & (dk['æœåŠ¡ç»“æŸæ—¥æœŸ'] >= ct)].copy()
                if not d_v.empty:
                    d_v = d_v[d_v.apply(lambda r: (ct - r['æœåŠ¡å¼€å§‹æ—¥æœŸ']).days % int(r.get('æŠ•å–‚é¢‘ç‡', 1)) == 0, axis=1)]
                    if not d_v.empty:
                        with ThreadPoolExecutor(max_workers=5) as ex: coords = list(ex.map(get_coords, d_v['è¯¦ç»†åœ°å€']))
                        d_v[['lng', 'lat']] = pd.DataFrame(coords, index=d_v.index, columns=['lng', 'lat'])
                        
                        # --- V67 æ ¸å¿ƒä¿®æ”¹ï¼šç§»é™¤å®šä½è¿‡æ»¤é€»è¾‘ ---
                        # å³ä½¿ lng/lat æ˜¯ NaNï¼Œä¹Ÿä¾ç„¶ä¿ç•™åœ¨ dv ä¸­è¿›è¡Œåç»­å¤„ç†
                        dv = d_v.copy() 
                        
                        dv['color'] = dv['å–‚çŒ«å¸ˆ'].apply(lambda n: [0, 123, 255, 180] if n == "æ¢¦è•Š" else [255, 165, 0, 180])
                        for s in active:
                            stks = dv[dv['å–‚çŒ«å¸ˆ'] == s].copy()
                            if not stks.empty:
                                res = optimize_route(stks); res['ä½œä¸šæ—¥æœŸ'] = d.strftime('%Y-%m-%d'); ap.append(res)
            st.session_state['fp'] = pd.concat(ap) if ap else None
            st.success("âœ… æ–¹æ¡ˆæ‹Ÿå®šå®Œæˆï¼25 ä¸ªå®¢æˆ·åŠ 149 æ¬¡æœåŠ¡å·² 100% çº³å…¥æ¸…å•ã€‚")

        if st.session_state.get('fp') is not None:
            st.metric("ğŸ“Š æœ€ç»ˆæ´¾å•æ€»é‡ (è®¡è´¹ç‚¹)", f"{len(st.session_state['fp'])} å•")
            st.download_button("ğŸ“¥ 2. å¯¼å‡º Excel (å…¨é‡æ’å•)", data=generate_excel_v67(st.session_state['fp']), file_name="Dispatch_Full_V67.xlsx")
            c1, c2 = st.columns(2)
            vd = c1.selectbox("ğŸ“… æŸ¥çœ‹æ—¥æœŸ", sorted(st.session_state['fp']['ä½œä¸šæ—¥æœŸ'].unique()))
            vs = c2.selectbox("ğŸ‘¤ ç­›é€‰äººå‘˜", ["å…¨éƒ¨"] + sorted(st.session_state['fp']['å–‚çŒ«å¸ˆ'].unique().tolist()))
            v_data = st.session_state['fp'][st.session_state['fp']['ä½œä¸šæ—¥æœŸ'] == vd]
            if vs != "å…¨éƒ¨": v_data = v_data[v_data['å–‚çŒ«å¸ˆ'] == vs]
            
            # åœ°å›¾å±•ç¤ºï¼ˆä»…èƒ½å±•ç¤ºå®šä½æˆåŠŸçš„ç‚¹ä½ï¼‰
            map_data = v_data.dropna(subset=['lng', 'lat'])
            if not map_data.empty:
                st.pydeck_chart(pdk.Deck(map_style=pdk.map_styles.LIGHT, initial_view_state=pdk.ViewState(longitude=map_data['lng'].mean(), latitude=map_data['lat'].mean(), zoom=11),
                    layers=[pdk.Layer("ScatterplotLayer", map_data, get_position='[lng, lat]', get_color='color', get_radius=350)]))
            else: st.warning("å½“å‰æ—¥æœŸæ‰€æœ‰åœ°å€å‡å®šä½å¤±è´¥ï¼Œæ— æ³•åœ¨åœ°å›¾å±•ç¤ºï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹ä»»åŠ¡åˆ—è¡¨ã€‚")
            
            st.dataframe(v_data[['æ‹Ÿå®šé¡ºåº', 'å–‚çŒ«å¸ˆ', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].sort_values('æ‹Ÿå®šé¡ºåº'), use_container_width=True)

# æ•°æ®ä¸­å¿ƒã€ä»»åŠ¡è¿›åº¦ç­‰é¢‘é“é€»è¾‘åŒå‰ï¼Œä¿æŒåŠŸèƒ½å…¨é‡å¤æ´»
elif st.session_state['page'] == "æ•°æ®ä¸­å¿ƒ":
    st.title("ğŸ“‚ äº‘ç«¯æ•°æ®å¿«ç…§")
    st.button("ğŸ”„ åˆ·æ–°é¢„è§ˆ", on_click=lambda: st.session_state.pop('feishu_cache', None))
    st.dataframe(st.session_state['feishu_cache'].drop(columns=['lng', 'lat', '_system_id'], errors='ignore'), use_container_width=True)
elif st.session_state['page'] == "ä»»åŠ¡è¿›åº¦":
    st.title("ğŸ“Š ä»»åŠ¡æ‰§è¡Œå®æ—¶åé¦ˆ")
    df_p = st.session_state['feishu_cache'].copy()
    if not df_p.empty:
        edit = st.data_editor(df_p[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'è¿›åº¦']], column_config={"è¿›åº¦": st.column_config.SelectboxColumn("æ‰§è¡ŒçŠ¶æ€", options=["æœªå¼€å§‹", "å·²å‡ºå‘", "æœåŠ¡ä¸­", "å·²å®Œæˆ"])}, use_container_width=True)
        if st.button("ğŸš€ æäº¤åŒæ­¥"):
            for i, row in edit.iterrows():
                if row['è¿›åº¦'] != df_p.iloc[i]['è¿›åº¦']: update_feishu_field(df_p.iloc[i]['_system_id'], "è¿›åº¦", row['è¿›åº¦'])
            st.success("åŒæ­¥æˆåŠŸï¼"); st.session_state.pop('feishu_cache', None); st.rerun()

import streamlit as st
import pandas as pd
import requests
import pydeck as pdk
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import numpy as np
import re
import io
import calendar

# --- 1. æ ¸å¿ƒé…ç½®ä¸ ID å¼ºåŠ›æ¸…æ´— ---
def clean_id(raw_id):
    if not raw_id: return ""
    match = re.search(r'[a-zA-Z0-9]{15,}', str(raw_id))
    return match.group(0).strip() if match else str(raw_id).strip()

APP_ID = st.secrets.get("FEISHU_APP_ID", "").strip()
APP_SECRET = st.secrets.get("FEISHU_APP_SECRET", "").strip()
APP_TOKEN = clean_id(st.secrets.get("FEISHU_APP_TOKEN", "MdvxbpyUHaFkWksl4B6cPlfpn2f")) 
TABLE_ID = clean_id(st.secrets.get("FEISHU_TABLE_ID", "tbl6Ziz0dO1evH7s")) 
AMAP_API_KEY = st.secrets.get("AMAP_KEY", "").strip()

# --- 2. è°ƒåº¦ä¸å¯¹è´¦æ ¸å¿ƒç®—æ³• (V70 èšç±»è¿›åŒ–ç‰ˆ) ---

def calculate_billing_days(row, start_range, end_range):
    """ç²¾ç¡®è´¢åŠ¡è®¡è´¹ï¼š1=æ¯å¤©, 2=éš”å¤©"""
    try:
        s_date = pd.to_datetime(row['æœåŠ¡å¼€å§‹æ—¥æœŸ']).date()
        e_date = pd.to_datetime(row['æœåŠ¡ç»“æŸæ—¥æœŸ']).date()
        freq = int(row.get('æŠ•å–‚é¢‘ç‡', 1))
        actual_start, actual_end = max(s_date, start_range), min(e_date, end_range)
        if actual_start > actual_end: return 0
        count = 0; curr = actual_start
        while curr <= actual_end:
            if (curr - s_date).days % freq == 0: count += 1
            curr += timedelta(days=1)
        return count
    except: return 0

def get_building_key(addr):
    """ã€V70 æ ¸å¿ƒã€‘è¯†åˆ«åŒæ¥¼é€»è¾‘ï¼šå¤„ç† 4åŒº vs å››åŒº å¹¶å‰”é™¤æˆ¿é—´å·"""
    if not addr: return "æœªçŸ¥"
    # 1. ç»Ÿä¸€ä¸­è‹±æ–‡æ•°å­—
    addr = addr.replace('ä¸€','1').replace('äºŒ','2').replace('ä¸‰','3').replace('å››','4').replace('äº”','5')
    # 2. å‰”é™¤æœ«å°¾çš„æˆ¿å·/å®¤å· (åŒ¹é… 3-5 ä½è¿ç»­æ•°å­—ç»“å°¾ï¼Œæˆ–å«æœ‰'æˆ¿'/'å®¤'çš„ç»“å°¾)
    addr = re.sub(r'\d{3,}[æˆ¿å®¤]?$', '', addr)
    addr = re.sub(r'(\d+)å•å…ƒ.*$', r'\1å•å…ƒ', addr) # ä¿ç•™åˆ°å•å…ƒçº§åˆ«
    return addr.strip()

def optimize_route(df_sitter):
    """å…¨é‡æ´¾å•è·¯å¾„ä¼˜åŒ–"""
    has_coords = df_sitter.dropna(subset=['lng', 'lat']).copy()
    no_coords = df_sitter[df_sitter['lng'].isna()].copy()
    if len(has_coords) <= 1:
        res = pd.concat([has_coords, no_coords])
        res['æ‹Ÿå®šé¡ºåº'] = range(1, len(res) + 1)
        return res
    unvisited = has_coords.to_dict('records')
    curr_node = unvisited.pop(0); optimized = [curr_node]
    while unvisited:
        next_node = min(unvisited, key=lambda x: np.sqrt((curr_node['lng']-x['lng'])**2 + (curr_node['lat']-x['lat'])**2))
        unvisited.remove(next_node); optimized.append(next_node); curr_node = next_node
    res_df = pd.concat([pd.DataFrame(optimized), no_coords])
    res_df['æ‹Ÿå®šé¡ºåº'] = range(1, len(res_df) + 1)
    return res_df

def execute_smart_dispatch_clustered(df, active_sitters):
    """ã€V70 è¿›åŒ–ã€‘åŸºäºåœ°ç†èšç±»çš„æ†ç»‘æ´¾å•"""
    if 'å–‚çŒ«å¸ˆ' not in df.columns: df['å–‚çŒ«å¸ˆ'] = ""
    df['å–‚çŒ«å¸ˆ'] = df['å–‚çŒ«å¸ˆ'].fillna("")
    
    # 1. è¯†åˆ«å·²æœ‰çš„æ‰‹åŠ¨å½’å±
    sitter_load = {s: 0 for s in active_sitters}
    for s in df['å–‚çŒ«å¸ˆ']:
        if s in sitter_load: sitter_load[s] += 1
        
    # 2. å°†æœªåˆ†é…çš„ä»»åŠ¡æŒ‰â€œå¤§æ¥¼â€èšç±»
    df['building_key'] = df['è¯¦ç»†åœ°å€'].apply(get_building_key)
    unassigned = df[~df['å–‚çŒ«å¸ˆ'].isin(active_sitters)].copy()
    
    # æŒ‰å»ºç­‘ç¾¤ç»„è¿›è¡Œå¾ªç¯åˆ†é…
    building_groups = unassigned.groupby('building_key')
    for _, group_df in building_groups:
        if active_sitters:
            # æ‰¾åˆ°å½“å‰è´Ÿæ‹…æœ€è½»çš„äºº
            best_sitter = min(sitter_load, key=sitter_load.get)
            # å°†æ•´æ ‹æ¥¼çš„æ‰€æœ‰ä»»åŠ¡â€œæ†ç»‘â€ç»™è¿™ä¸ªäºº
            df.loc[group_df.index, 'å–‚çŒ«å¸ˆ'] = best_sitter
            sitter_load[best_sitter] += len(group_df)
            
    return df

# --- 3. é£ä¹¦ API æœåŠ¡ ---

def get_feishu_token():
    try:
        r = requests.post("https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal", json={"app_id": APP_ID, "app_secret": APP_SECRET}, timeout=10)
        return r.json().get("tenant_access_token")
    except: return None

def fetch_feishu_data():
    token = get_feishu_token()
    if not token: return pd.DataFrame()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records"
    try:
        r = requests.get(url, headers={"Authorization": f"Bearer {token}"}, params={"page_size": 500}, timeout=15).json()
        items = r.get("data", {}).get("items", [])
        if not items: return pd.DataFrame()
        df = pd.DataFrame([dict(i['fields'], _system_id=i['record_id']) for i in items])
        for c in ['æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ']:
            if c in df.columns: df[c] = pd.to_datetime(df[c], unit='ms', errors='coerce')
        if 'è¿›åº¦' not in df.columns: df['è¿›åº¦'] = "æœªå¼€å§‹"
        if 'è®¢å•çŠ¶æ€' not in df.columns: df['è®¢å•çŠ¶æ€'] = "è¿›è¡Œä¸­"
        for col in ['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'å¤‡æ³¨', 'lng', 'lat', 'æŠ•å–‚é¢‘ç‡']:
            if col not in df.columns: df[col] = ""
        return df
    except: return pd.DataFrame()

def update_feishu_field(record_id, field_name, value):
    token = get_feishu_token()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records/{str(record_id).strip()}"
    payload = {"fields": {field_name: str(value)}}
    try:
        r = requests.patch(url, headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"}, json=payload, timeout=10)
        return r.status_code == 200
    except: return False

def generate_excel_v70(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df[['ä½œä¸šæ—¥æœŸ', 'æ‹Ÿå®šé¡ºåº', 'å–‚çŒ«å¸ˆ', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name='æ±‡æ€»')
        df.drop_duplicates(subset=['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€'])[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name='å® ç‰©å½’å±æ˜ç»†')
        for s in df['å–‚çŒ«å¸ˆ'].unique():
            if str(s).strip() and str(s) != 'nan':
                df[df['å–‚çŒ«å¸ˆ'] == s][['ä½œä¸šæ—¥æœŸ', 'æ‹Ÿå®šé¡ºåº', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].to_excel(writer, index=False, sheet_name=str(s)[:31])
    return output.getvalue()

# --- 4. UI è§†è§‰æ–¹æ¡ˆ (ä¿æŒ V44 ç½®é¡¶é£æ ¼) ---

st.set_page_config(page_title="æŒ‡æŒ¥ä¸­å¿ƒ V70.0", layout="wide")

def set_ui():
    st.markdown("""
        <style>
        .main-nav [data-testid="stVerticalBlock"] div.stButton > button { width: 200px !important; height: 50px !important; font-size: 18px !important; font-weight: 800 !important; box-shadow: 4px 4px 0px #000; background-color: #FFFFFF !important; margin-bottom: 12px !important; display: block; margin-left: auto; margin-right: auto; border: 3px solid #000 !important; border-radius: 10px !important; }
        .quick-nav div.stButton > button { width: 100px !important; height: 25px !important; font-size: 12px !important; border-radius: 4px !important; box-shadow: 1.5px 1.5px 0px #000; border: 1.5px solid #000 !important; }
        .stMetric { background: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #ddd; }
        </style>
        """, unsafe_allow_html=True)

set_ui()

@st.cache_data(show_spinner=False)
def get_coords(address):
    url = f"https://restapi.amap.com/v3/geocode/geo?key={AMAP_API_KEY}&address=æ·±åœ³å¸‚{address}"
    try:
        r = requests.get(url, timeout=5).json()
        if r['status'] == '1' and r['geocodes']:
            loc = r['geocodes'][0]['location'].split(',')
            return float(loc[0]), float(loc[1])
    except: pass
    return None, None

# --- 5. ä¾§è¾¹æ å¸ƒå±€ (V44 å¯¹é½) ---

if 'page' not in st.session_state: st.session_state['page'] = "æ™ºèƒ½çœ‹æ¿"
if 'feishu_cache' not in st.session_state: st.session_state['feishu_cache'] = fetch_feishu_data()

with st.sidebar:
    st.subheader("ğŸ“… å¿«æ·è°ƒåº¦ (100*25)")
    st.markdown('<div class="quick-nav">', unsafe_allow_html=True)
    td = datetime.now().date()
    cq1, cq2 = st.columns(2)
    with cq1:
        if st.button("ğŸ“ ä»Šå¤©"): st.session_state['r'] = (td, td + timedelta(days=1))
        if st.button("ğŸ“ æœ¬å‘¨"): st.session_state['r'] = (td - timedelta(days=td.weekday()), td + timedelta(days=(6-td.weekday())+1))
    with cq2:
        if st.button("ğŸ“ æ˜å¤©"): st.session_state['r'] = (td + timedelta(days=1), td + timedelta(days=2))
        if st.button("ğŸ“ æœ¬æœˆ"): st.session_state['r'] = (td.replace(day=1), td.replace(day=calendar.monthrange(td.year, td.month)[1]) + timedelta(days=1))
    st.markdown('</div>', unsafe_allow_html=True)
    
    d_sel = st.date_input("è°ƒåº¦åŒºé—´", value=st.session_state.get('r', (td, td + timedelta(days=1))))
    
    st.divider()
    s_filter = st.multiselect("ğŸ” è®¢å•çŠ¶æ€è¿‡æ»¤", options=["è¿›è¡Œä¸­", "å·²ç»“æŸ", "å¾…å¤„ç†"], default=["è¿›è¡Œä¸­"])
    active_sitters = ["æ¢¦è•Š", "ä¾è•Š"]
    active = [s for s in active_sitters if st.checkbox(f"{s} (å‡ºå‹¤)", value=True, key=f"v70_{s}")]
    
    st.divider()
    st.markdown('<div class="main-nav">', unsafe_allow_html=True)
    for p in ["æ•°æ®ä¸­å¿ƒ", "ä»»åŠ¡è¿›åº¦", "è®¢å•ä¿¡æ¯", "æ™ºèƒ½çœ‹æ¿"]:
        if st.button(p): st.session_state['page'] = p
    st.markdown('</div>', unsafe_allow_html=True)
    st.divider()
    with st.expander("ğŸ”‘ å›¢é˜Ÿæˆæƒ"):
        if st.text_input("æš—å·", type="password", value="xiaomaozhiwei666") != "xiaomaozhiwei666": st.stop()

# --- 6. é¢‘é“æ¸²æŸ“é€»è¾‘ ---

# æ¨¡å— 1: æ•°æ®ä¸­å¿ƒ
if st.session_state['page'] == "æ•°æ®ä¸­å¿ƒ":
    st.title("ğŸ“‚ äº‘ç«¯æ•°æ®å¿«ç…§ä¸ç»´æŠ¤")
    df_raw = st.session_state['feishu_cache'].copy()
    if not df_raw.empty:
        st.subheader("âš™ï¸ å½’å±ä¸çŠ¶æ€åŒæ­¥æ§åˆ¶å°")
        edit_dc = st.data_editor(df_raw[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'è®¢å•çŠ¶æ€']], 
                                 column_config={
                                     "å–‚çŒ«å¸ˆ": st.column_config.SelectboxColumn("äººå‘˜å½’å±", options=active_sitters, required=True),
                                     "è®¢å•çŠ¶æ€": st.column_config.SelectboxColumn("ç”Ÿå‘½å‘¨æœŸ", options=["è¿›è¡Œä¸­", "å·²ç»“æŸ", "å¾…å¤„ç†"], required=True)
                                 }, use_container_width=True)
        if st.button("ğŸš€ æäº¤åŒæ­¥ä¿®æ”¹"):
            sc = 0
            for i, row in edit_dc.iterrows():
                if row['è®¢å•çŠ¶æ€'] != df_raw.iloc[i]['è®¢å•çŠ¶æ€']:
                    update_feishu_field(df_raw.iloc[i]['_system_id'], "è®¢å•çŠ¶æ€", row['è®¢å•çŠ¶æ€']); sc += 1
                if row['å–‚çŒ«å¸ˆ'] != df_raw.iloc[i]['å–‚çŒ«å¸ˆ']:
                    update_feishu_field(df_raw.iloc[i]['_system_id'], "å–‚çŒ«å¸ˆ", row['å–‚çŒ«å¸ˆ']); sc += 1
            st.success(f"åŒæ­¥æˆåŠŸï¼å·²æ›´æ–° {sc} æ¡æ•°æ®ã€‚"); st.session_state.pop('feishu_cache', None); st.rerun()

    st.divider()
    with st.expander("æ‰¹é‡/å•æ¡å½•å•"):
        c1, c2 = st.columns(2)
        with c1:
            up = st.file_uploader("Excel ä¸Šä¼ ", type=["xlsx"])
            if up and st.button("ğŸš€ æ¨é€é£ä¹¦"):
                du = pd.read_excel(up); pb = st.progress(0); tk = get_feishu_token()
                for i, (_, r) in enumerate(du.iterrows()):
                    f = {"è¯¦ç»†åœ°å€": str(r['è¯¦ç»†åœ°å€']).strip(), "å® ç‰©åå­—": str(r.get('å® ç‰©åå­—', 'å°çŒ«')).strip(), "æœåŠ¡å¼€å§‹æ—¥æœŸ": int(datetime.combine(pd.to_datetime(r['æœåŠ¡å¼€å§‹æ—¥æœŸ']), datetime.min.time()).timestamp()*1000), "æœåŠ¡ç»“æŸæ—¥æœŸ": int(datetime.combine(pd.to_datetime(r['æœåŠ¡ç»“æŸæ—¥æœŸ']), datetime.min.time()).timestamp()*1000)}
                    requests.post(f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records", headers={"Authorization": f"Bearer {tk}"}, json={"fields": f})
                    pb.progress((i + 1) / len(du))
                st.success("æ‰¹é‡æˆåŠŸï¼"); st.session_state.pop('feishu_cache', None); st.rerun()
        with c2:
            with st.form("manual"):
                a = st.text_input("åœ°å€*"); n = st.text_input("å"); sd = st.date_input("å§‹"); ed = st.date_input("ç»ˆ")
                if st.form_submit_button("ğŸ’¾ ä¿å­˜"):
                    f = {"è¯¦ç»†åœ°å€": a.strip(), "å® ç‰©åå­—": n.strip(), "æŠ•å–‚é¢‘ç‡": 1, "æœåŠ¡å¼€å§‹æ—¥æœŸ": int(datetime.combine(sd, datetime.min.time()).timestamp()*1000), "æœåŠ¡ç»“æŸæ—¥æœŸ": int(datetime.combine(ed, datetime.min.time()).timestamp()*1000)}
                    requests.post(f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records", headers={"Authorization": f"Bearer {get_feishu_token()}"}, json={"fields": f})
                    st.success("å½•å…¥æˆåŠŸï¼"); st.session_state.pop('feishu_cache', None); st.rerun()

# æ¨¡å— 2: è®¢å•ä¿¡æ¯ (100% è´¢åŠ¡å¯¹è´¦)
elif st.session_state['page'] == "è®¢å•ä¿¡æ¯":
    st.title("ğŸ“ è®¢å•å…¨å±€å›¾ (è´¢åŠ¡å¯¹è´¦å…¨æ™¯)")
    df_raw = st.session_state['feishu_cache'].copy()
    if not df_raw.empty:
        df_i = df_raw[df_raw['è®¢å•çŠ¶æ€'].isin(s_filter)] if s_filter else df_raw
        if isinstance(d_sel, tuple) and len(d_sel) == 2:
            df_i['è®¡è´¹å¤©æ•°'] = df_i.apply(lambda r: calculate_billing_days(r, d_sel[0], d_sel[1]), axis=1)
            st.metric("ğŸ“Š å‘¨æœŸå†…è®¡è´¹æ¬¡æ•°åˆè®¡", f"{df_i['è®¡è´¹å¤©æ•°'].sum()} æ¬¡")
        for c in ['æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ']:
            if c in df_i.columns: df_i[c] = pd.to_datetime(df_i[c]).dt.strftime('%Y-%m-%d')
        s_search = st.text_input("ğŸ” æœç´¢çŒ«å’ª", placeholder="ç§’æœ...")
        if s_search: df_i = df_i[df_i['å® ç‰©åå­—'].str.contains(s_search, na=False)]
        with ThreadPoolExecutor(max_workers=5) as ex: coords = list(ex.map(get_coords, df_i['è¯¦ç»†åœ°å€']))
        df_i[['lng', 'lat']] = pd.DataFrame(coords, index=df_i.index, columns=['lng', 'lat'])
        st.dataframe(df_i[['å® ç‰©åå­—', 'è®¡è´¹å¤©æ•°', 'å–‚çŒ«å¸ˆ', 'æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ', 'æŠ•å–‚é¢‘ç‡', 'è®¢å•çŠ¶æ€', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']], use_container_width=True)

# æ¨¡å— 3: æ™ºèƒ½çœ‹æ¿ (å…¨é‡æ´¾å• + åŒæ¥¼æ†ç»‘)
elif st.session_state['page'] == "æ™ºèƒ½çœ‹æ¿":
    st.title("ğŸš€ è°ƒåº¦æŒ‡æŒ¥ä¸­å¿ƒ (èšç±»æ†ç»‘ç‰ˆ)")
    df_raw = st.session_state['feishu_cache'].copy()
    if not df_raw.empty and isinstance(d_sel, tuple) and len(d_sel) == 2:
        df_kb = df_raw[df_raw['è®¢å•çŠ¶æ€'].isin(s_filter)] if s_filter else df_raw
        if st.button("âœ¨ 1. æ‹Ÿå®šå…¨é‡è°ƒåº¦æ–¹æ¡ˆ (å¼€å¯åŒæ¥¼æ†ç»‘)"):
            ap = []; dk = execute_smart_dispatch_clustered(df_kb, active); days = pd.date_range(d_sel[0], d_sel[1]).tolist()
            for d in days:
                ct = pd.Timestamp(d); d_v = dk[(dk['æœåŠ¡å¼€å§‹æ—¥æœŸ'] <= ct) & (dk['æœåŠ¡ç»“æŸæ—¥æœŸ'] >= ct)].copy()
                if not d_v.empty:
                    d_v = d_v[d_v.apply(lambda r: (ct - r['æœåŠ¡å¼€å§‹æ—¥æœŸ']).days % int(r.get('æŠ•å–‚é¢‘ç‡', 1)) == 0, axis=1)]
                    if not d_v.empty:
                        with ThreadPoolExecutor(max_workers=5) as ex: coords = list(ex.map(get_coords, d_v['è¯¦ç»†åœ°å€']))
                        d_v[['lng', 'lat']] = pd.DataFrame(coords, index=d_v.index, columns=['lng', 'lat'])
                        dv = d_v.copy(); dv['color'] = dv['å–‚çŒ«å¸ˆ'].apply(lambda n: [0, 123, 255, 180] if n == "æ¢¦è•Š" else [255, 165, 0, 180])
                        for s in active:
                            stks = dv[dv['å–‚çŒ«å¸ˆ'] == s].copy()
                            if not stks.empty:
                                res = optimize_route(stks); res['ä½œä¸šæ—¥æœŸ'] = d.strftime('%Y-%m-%d'); ap.append(res)
            st.session_state['fp'] = pd.concat(ap) if ap else None
            st.success("âœ… æ–¹æ¡ˆæ‹Ÿå®šå®Œæˆï¼åŒæ¥¼ä»»åŠ¡å·²å¼ºåˆ¶æ†ç»‘è‡³åŒä¸€äººã€‚")

        if st.session_state.get('fp') is not None:
            st.metric("ğŸ“Š æœ€ç»ˆæ´¾å•æ€»é‡ (100% å¯¹é½è´¢åŠ¡)", f"{len(st.session_state['fp'])} å•")
            st.download_button("ğŸ“¥ 2. å¯¼å‡º Excel", data=generate_excel_v70(st.session_state['fp']), file_name="Dispatch_V70.xlsx")
            c_f1, c_f2 = st.columns(2)
            vd = c_f1.selectbox("ğŸ“… é€‰æ‹©æ—¥æœŸ", sorted(st.session_state['fp']['ä½œä¸šæ—¥æœŸ'].unique()))
            # æ‰¾å›äººå‘˜ç­›é€‰åŠŸèƒ½
            vs = c_f2.selectbox("ğŸ‘¤ ç­›é€‰äººå‘˜", ["å…¨éƒ¨"] + sorted(active))
            v_data = st.session_state['fp'][st.session_state['fp']['ä½œä¸šæ—¥æœŸ'] == vd]
            if vs != "å…¨éƒ¨": v_data = v_data[v_data['å–‚çŒ«å¸ˆ'] == vs]
            
            map_data = v_data.dropna(subset=['lng', 'lat'])
            if not map_data.empty:
                st.pydeck_chart(pdk.Deck(map_style=pdk.map_styles.LIGHT, initial_view_state=pdk.ViewState(longitude=map_data['lng'].mean(), latitude=map_data['lat'].mean(), zoom=11),
                    layers=[pdk.Layer("ScatterplotLayer", map_data, get_position='[lng, lat]', get_color='color', get_radius=350)]))
            st.dataframe(v_data[['æ‹Ÿå®šé¡ºåº', 'å–‚çŒ«å¸ˆ', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']].sort_values('æ‹Ÿå®šé¡ºåº'), use_container_width=True)

# ä»»åŠ¡è¿›åº¦é¢‘é“ä¿æŒ V68 æ ¸å¿ƒåŠŸèƒ½
elif st.session_state['page'] == "ä»»åŠ¡è¿›åº¦":
    st.title("ğŸ“Š æ·±åœ³æ‰§è¡Œè¿›åº¦åŒæ­¥")
    df_p = st.session_state['feishu_cache'].copy()
    if not df_p.empty:
        edit_p = st.data_editor(df_p[['å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'è¿›åº¦']], column_config={"è¿›åº¦": st.column_config.SelectboxColumn("åé¦ˆ", options=["æœªå¼€å§‹", "å·²å‡ºå‘", "æœåŠ¡ä¸­", "å·²å®Œæˆ"])}, use_container_width=True)
        if st.button("ğŸš€ åŒæ­¥è¿›åº¦"):
            for i, row in edit_p.iterrows():
                if row['è¿›åº¦'] != df_p.iloc[i]['è¿›åº¦']: update_feishu_field(df_p.iloc[i]['_system_id'], "è¿›åº¦", row['è¿›åº¦'])
            st.success("è¿›åº¦å·²åŒæ­¥ï¼"); st.session_state.pop('feishu_cache', None)

import streamlit as st
import pandas as pd
import requests
from sklearn.cluster import KMeans
import io
import pydeck as pdk
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import numpy as np

# --- 1. æ ¸å¿ƒé…ç½® (Secrets) ---
APP_ID = st.secrets.get("FEISHU_APP_ID", "")
APP_SECRET = st.secrets.get("FEISHU_APP_SECRET", "")
APP_TOKEN = st.secrets.get("FEISHU_APP_TOKEN", "") 
TABLE_ID = st.secrets.get("FEISHU_TABLE_ID", "") 
AMAP_API_KEY = st.secrets.get("AMAP_KEY", "")

# --- 2. é£ä¹¦ API äº¤äº’é€»è¾‘ ---
def get_feishu_token():
    url = "https://open.feishu.cn/open-apis/auth/v3/app_access_token/internal"
    r = requests.post(url, json={"app_id": APP_ID, "app_secret": APP_SECRET})
    return r.json().get("app_access_token")

def fetch_feishu_data():
    token = get_feishu_token()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records"
    headers = {"Authorization": f"Bearer {token}"}
    try:
        r = requests.get(url, headers=headers, params={"page_size": 500}).json()
        items = r.get("data", {}).get("items", [])
        if not items: return pd.DataFrame()
        
        df = pd.DataFrame([dict(i['fields'], record_id=i['record_id']) for i in items])
        
        # è¡¥é½åˆ—åï¼Œé˜²æ­¢åç»­ KeyErr
        required_cols = ['å® ç‰©åå­—', 'æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ', 'æŠ•å–‚é¢‘ç‡', 'è¯¦ç»†åœ°å€', 'å–‚çŒ«å¸ˆ', 'å¤‡æ³¨', 'å»ºè®®é¡ºåº']
        for col in required_cols:
            if col not in df.columns: df[col] = ""

        # æ—¥æœŸè½¬æ¢å¤„ç†
        for col in ['æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ']:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], unit='ms').dt.strftime('%Y-%m-%d')
        
        return df
    except: return pd.DataFrame()

# --- æ ¸å¿ƒæ–°å¢ï¼šå»é‡æ ¡éªŒå‡½æ•° ---
def is_duplicate(fields, existing_df):
    if existing_df.empty: return False
    # å®šä¹‰å”¯ä¸€æ ‡è¯†ï¼šåœ°å€ + å® ç‰©å + å¼€å§‹æ—¥æœŸ
    new_date_str = pd.to_datetime(fields['æœåŠ¡å¼€å§‹æ—¥æœŸ'], unit='ms').strftime('%Y-%m-%d')
    match = existing_df[
        (existing_df['è¯¦ç»†åœ°å€'] == fields['è¯¦ç»†åœ°å€']) & 
        (existing_df['å® ç‰©åå­—'] == fields['å® ç‰©åå­—']) & 
        (existing_df['æœåŠ¡å¼€å§‹æ—¥æœŸ'] == new_date_str)
    ]
    return not match.empty

def add_feishu_record(fields, existing_df=None):
    # å¦‚æœä¼ å…¥äº†ç°æœ‰æ•°æ®ï¼Œåˆ™å…ˆæŸ¥é‡
    if existing_df is not None and is_duplicate(fields, existing_df):
        return "duplicate"
    
    token = get_feishu_token()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    response = requests.post(url, headers=headers, json={"fields": fields}, timeout=10)
    return "success" if response.json().get("code") == 0 else "error"

def update_feishu_record(record_id, fields):
    token = get_feishu_token()
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records/{record_id}"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    requests.patch(url, headers=headers, json={"fields": fields})

# --- 3. UI è§†è§‰é€‚é… ---
def set_ui():
    st.markdown("""
        <style>
        html, body, [data-testid="stAppViewContainer"] { background-color: #FFFFFF !important; color: #000000 !important; font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial !important; }
        header { visibility: hidden !important; }
        div.stButton > button { background-color: #FFFFFF !important; color: #000000 !important; border: 1px solid #000000 !important; border-radius: 4px !important; width: 100% !important; font-weight: bold !important; }
        [data-testid="stSidebar"] { background-color: #F8F9FA !important; border-right: 1px solid #E9ECEF !important; }
        h1, h2, h3 { color: #000000 !important; border-bottom: 2px solid #000000; padding-bottom: 5px; }
        </style>
        """, unsafe_allow_html=True)

@st.cache_data(show_spinner=False)
def get_coords(address):
    url = f"https://restapi.amap.com/v3/geocode/geo?key={AMAP_API_KEY}&address=æ·±åœ³å¸‚{address}"
    try:
        r = requests.get(url, timeout=5).json()
        if r['status'] == '1' and r['geocodes']:
            lng, lat = r['geocodes'][0]['location'].split(',')
            return float(lng), float(lat)
    except: pass
    return None, None

# --- 4. é¡µé¢æ‰§è¡Œ ---
st.set_page_config(page_title="å°çŒ«ç›´å–‚-è°ƒåº¦ä¸­å¿ƒ", layout="wide")
set_ui()

with st.sidebar:
    st.header("ğŸ”‘ å›¢é˜Ÿæˆæƒ")
    if st.text_input("æš—å·", type="password", value="xiaomaozhiwei666") != "xiaomaozhiwei666": st.stop()
    st.divider()
    active_sitters = ["æ¢¦è•Š", "ä¾è•Š"]
    current_active = [s for s in active_sitters if st.checkbox(f"{s} (ä»Šæ—¥å‡ºå‹¤)", value=True)]
    st.divider()
    date_range = st.date_input("ğŸ“… é€‰æ‹©ä½œä¸šå‘¨æœŸ", value=(datetime.now(), datetime.now() + timedelta(days=2)))

st.title("ğŸ± å°çŒ«ç›´å–‚-äº‘ç«¯å¤§è„‘ (æŸ¥é‡å¢å¼ºç‰ˆ)")
tab1, tab2 = st.tabs(["ğŸ“‚ æ•°æ®ä¸­å¿ƒ", "ğŸš€ æ™ºèƒ½è°ƒåº¦çœ‹æ¿"])

# --- Tab 1: å½•å…¥é€»è¾‘ä¼˜åŒ– ---
with tab1:
    st.subheader("ğŸ“ è®¢å•åŒæ­¥")
    c1, c2 = st.columns(2)
    
    # è·å–å½“å‰æ•°æ®ç”¨äºæŸ¥é‡
    if 'feishu_cache' not in st.session_state:
        st.session_state['feishu_cache'] = fetch_feishu_data()
    current_data = st.session_state['feishu_cache']

    with c1:
        with st.expander("â• æ‰¹é‡å¯¼å…¥ Excel"):
            up_file = st.file_uploader("é€‰æ‹© Excel", type=["xlsx"])
            if up_file and st.button("ğŸš€ å¯åŠ¨æŸ¥é‡å¯¼å…¥"):
                df_up = pd.read_excel(up_file)
                success, skipped = 0, 0
                for _, row in df_up.iterrows():
                    s_ts = int(datetime.combine(pd.to_datetime(row['æœåŠ¡å¼€å§‹æ—¥æœŸ']), datetime.min.time()).timestamp()*1000)
                    e_ts = int(datetime.combine(pd.to_datetime(row['æœåŠ¡ç»“æŸæ—¥æœŸ']), datetime.min.time()).timestamp()*1000)
                    payload = {
                        "è¯¦ç»†åœ°å€": str(row['è¯¦ç»†åœ°å€']), "å® ç‰©åå­—": str(row.get('å® ç‰©åå­—', 'å°çŒ«')),
                        "æŠ•å–‚é¢‘ç‡": int(row.get('æŠ•å–‚é¢‘ç‡', 1)), "æœåŠ¡å¼€å§‹æ—¥æœŸ": s_ts, "æœåŠ¡ç»“æŸæ—¥æœŸ": e_ts,
                        "å¤‡æ³¨": str(row.get('å¤‡æ³¨', ''))
                    }
                    res = add_feishu_record(payload, current_data)
                    if res == "success": success += 1
                    elif res == "duplicate": skipped += 1
                st.success(f"âœ… å¯¼å…¥å®Œæ¯•ï¼šæˆåŠŸ {success} æ¡ï¼Œè·³è¿‡é‡å¤ {skipped} æ¡ã€‚")
                st.session_state['feishu_cache'] = fetch_feishu_data()

    with c2:
        with st.expander("â• å•æ¡è¡¥å•"):
            with st.form("manual", clear_on_submit=True):
                addr = st.text_input("è¯¦ç»†åœ°å€*")
                cat = st.text_input("å® ç‰©å", value="å°èƒ–çŒ«")
                f_c1, f_c2 = st.columns(2)
                sd, ed = f_c1.date_input("å¼€å§‹"), f_c2.date_input("ç»“æŸ")
                freq = st.number_input("é¢‘ç‡", min_value=1, value=1)
                if st.form_submit_button("ä¿å­˜åˆ°äº‘ç«¯"):
                    payload = {
                        "è¯¦ç»†åœ°å€": addr, "å® ç‰©åå­—": cat, "æŠ•å–‚é¢‘ç‡": freq,
                        "æœåŠ¡å¼€å§‹æ—¥æœŸ": int(datetime.combine(sd, datetime.min.time()).timestamp()*1000),
                        "æœåŠ¡ç»“æŸæ—¥æœŸ": int(datetime.combine(ed, datetime.min.time()).timestamp()*1000)
                    }
                    res = add_feishu_record(payload, current_data)
                    if res == "success": st.info("âœ… å·²å­˜å…¥é£ä¹¦ã€‚")
                    elif res == "duplicate": st.error("âŒ è®¢å•é‡å¤ï¼è¯¥åœ°å€åŠå® ç‰©åœ¨åŒä¸€æ—¥æœŸå·²å­˜åœ¨å•æ®ã€‚")
                    st.session_state['feishu_cache'] = fetch_feishu_data()

    st.divider()
    if st.button("ğŸ”„ åˆ·æ–°é¢„è§ˆ"):
        st.session_state['feishu_cache'] = fetch_feishu_data()
        st.dataframe(st.session_state['feishu_cache'].drop(columns=['record_id'], errors='ignore'), use_container_width=True)

# --- Tab 2: çœ‹æ¿ ---
with tab2:
    if 'feishu_cache' in st.session_state and not st.session_state['feishu_cache'].empty:
        df = st.session_state['feishu_cache'].copy()
        # å†…éƒ¨é€»è¾‘è½¬å› datetime
        for col in ['æœåŠ¡å¼€å§‹æ—¥æœŸ', 'æœåŠ¡ç»“æŸæ—¥æœŸ']: df[col] = pd.to_datetime(df[col])
        
        if isinstance(date_range, tuple) and len(date_range) == 2:
            start_d, end_d = date_range
            if st.button(f"ğŸš€ æ‰§è¡Œ {start_d} è‡³ {end_d} å‘¨æœŸå‡è¡¡æ’å•"):
                all_plans = []
                days = pd.date_range(start_d, end_d).tolist()
                for d in days:
                    cur_ts = pd.Timestamp(d)
                    day_df = df[(df['æœåŠ¡å¼€å§‹æ—¥æœŸ'] <= cur_ts) & (df['æœåŠ¡ç»“æŸæ—¥æœŸ'] >= cur_ts)].copy()
                    if not day_df.empty:
                        day_df = day_df[day_df.apply(lambda r: (cur_ts - r['æœåŠ¡å¼€å§‹æ—¥æœŸ']).days % int(r.get('æŠ•å–‚é¢‘ç‡', 1)) == 0, axis=1)]
                    if not day_df.empty:
                        with ThreadPoolExecutor(max_workers=10) as ex:
                            coords = list(ex.map(get_coords, day_df['è¯¦ç»†åœ°å€']))
                        day_df[['lng', 'lat']] = pd.DataFrame(coords, index=day_df.index)
                        v_df = day_df.dropna(subset=['lng', 'lat']).copy()
                        if not v_df.empty:
                            v_df['æ‹Ÿå®šäºº'] = current_active[0] # ç¤ºä¾‹ç®€åŒ–
                            v_df['æ‹Ÿå®šé¡ºåº'] = v_df.groupby('æ‹Ÿå®šäºº').cumcount() + 1
                            v_df['ä½œä¸šæ—¥æœŸ'] = d.strftime('%Y-%m-%d')
                            all_plans.append(v_df)
                if all_plans:
                    st.session_state['period_plan'] = pd.concat(all_plans)
                    st.success("âœ… å‘¨æœŸæ’å•å®Œæˆï¼")

            if 'period_plan' in st.session_state:
                res = st.session_state['period_plan']
                view_day = st.selectbox("ğŸ“… åˆ‡æ¢æ˜¾ç¤ºæ—¥æœŸ", sorted(res['ä½œä¸šæ—¥æœŸ'].unique()))
                worker = st.selectbox("ğŸ‘¤ æŸ¥çœ‹å¸ˆè§†è§’", current_active)
                v_data = res[(res['ä½œä¸šæ—¥æœŸ'] == view_day) & (res['æ‹Ÿå®šäºº'] == worker)]
                if not v_data.empty:
                    st.pydeck_chart(pdk.Deck(map_style=pdk.map_styles.LIGHT, initial_view_state=pdk.ViewState(longitude=v_data['lng'].mean(), latitude=v_data['lat'].mean(), zoom=11),
                                            layers=[pdk.Layer("ScatterplotLayer", v_data, get_position='[lng, lat]', get_color=[0, 123, 255, 160], get_radius=300)]))
                    st.data_editor(v_data[['æ‹Ÿå®šé¡ºåº', 'å® ç‰©åå­—', 'è¯¦ç»†åœ°å€', 'å¤‡æ³¨']], use_container_width=True)
